{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file for PO_HBA: D:\\Data for Stock Report\\cleaned_PO_pending_HBA.xlsx\n",
      "Loading file for PO_Import: D:\\Data for Stock Report\\cleaned_PO_pending_import_party.xlsx\n",
      "Loading file for Access_PO: D:\\Data for Stock Report\\cleaned_PO_pending_other.xlsx\n",
      "Connection successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thanawit C\\AppData\\Local\\Temp\\ipykernel_15464\\3297622898.py:123: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  access_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Access database is closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thanawit C\\AppData\\Local\\Temp\\ipykernel_15464\\3297622898.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  owner_scm_df_selected['CJ_Item'] = owner_scm_df_selected['CJ_Item'].fillna('')\n",
      "C:\\Users\\Thanawit C\\AppData\\Local\\Temp\\ipykernel_15464\\3297622898.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  owner_scm_df_selected['CJ_Item'] = owner_scm_df_selected['CJ_Item'].apply(lambda x: x.split('.')[0] if '.0' in str(x) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine all po pending has been saved to: D:\\Data for Stock Report\\Raw_PO_pending.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pyodbc\n",
    "\n",
    "# Collect PO Pending Raw\n",
    "po_file_path = {  \n",
    "    'PO_HBA': r'D:\\Data for Stock Report\\cleaned_PO_pending_HBA.xlsx',  \n",
    "    'PO_Import': r'D:\\Data for Stock Report\\cleaned_PO_pending_import_party.xlsx',  \n",
    "    'Access_PO': r'D:\\Data for Stock Report\\cleaned_PO_pending_other.xlsx',  \n",
    "}\n",
    "\n",
    "# Load excel to DF from the specified sheet name\n",
    "def load_data(po_file_path):\n",
    "    dataframes = {}\n",
    "    for key, path in po_file_path.items():\n",
    "        print(f\"Loading file for {key}: {path}\")\n",
    "        dataframes[key] = pd.read_excel(path, sheet_name='cleaned data')\n",
    "    return dataframes\n",
    "\n",
    "# Clean data for PO_HBA\n",
    "def clean_po_hba(df):\n",
    "    # Exclude unnecessary columns\n",
    "    df = df.drop(columns=['Sold to', 'สถานที่จัดส่งสินค้า'])\n",
    "    # Rename columns\n",
    "    df.rename(columns={\n",
    "        'SHM_Article': 'SHM_Item',\n",
    "        'CJ_Article': 'CJ_Item',\n",
    "        'SHM PO Date': 'PO Date',\n",
    "        'SHM PO NO.': 'SHM PO No.',\n",
    "        'CJ/TD PO.NO': 'PO CJ No.',\n",
    "        'DC': 'Ship to DC',\n",
    "        'วันที่โรงงานคอนเฟิร์มส่งสินค้า': 'Delivery Date',\n",
    "        'สถานะการจัดส่งสินค้า': 'Delivery_Status',\n",
    "        'หน่วยบรรจุ (ชิ้น/ลัง)': 'PC_Cartons',\n",
    "        'จำนวนเปิด PO สหมิตร (ลัง)': 'PO Cartons',\n",
    "        'จำนวนเปิด PO สหมิตร (ชิ้น)': 'PO_Qty',\n",
    "        'Supplier (Short name)': 'Supplier Name'\n",
    "    }, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Clean data for PO_Import\n",
    "def clean_po_import(df):\n",
    "    # Unpivot the data\n",
    "    df_unpivoted = df.melt(\n",
    "        id_vars=['SHM_Item', 'CJ_Item', 'Product Name', 'PO CJ No.', 'เรือ ETA', 'PC_Cartons'],\n",
    "        value_vars=['Date_to_DC1', 'cartons_to_DC1', 'Date_to_DC2', 'cartons_to_DC2', 'Date_to_DC4', 'cartons_to_DC4', \n",
    "                    'PO_Qty_to_DC1', 'PO_Qty_to_DC2', 'PO_Qty_to_DC4'],\n",
    "        var_name='variable',\n",
    "        value_name='value'\n",
    "    )\n",
    "\n",
    "    # Extract 'Ship to DC', 'PO Cartons', 'PO qty', and 'Date to DC' from the variable column\n",
    "    df_unpivoted['Ship to DC'] = df_unpivoted['variable'].apply(\n",
    "        lambda x: 'DC1' if 'DC1' in x else ('DC2' if 'DC2' in x else 'DC4'))\n",
    "    df_unpivoted['PO Cartons'] = df_unpivoted.apply(lambda row: row['value'] if 'cartons' in row['variable'] else None, axis=1)\n",
    "    df_unpivoted['PO qty'] = df_unpivoted.apply(lambda row: row['value'] if 'PO_Qty' in row['variable'] else None, axis=1)\n",
    "    df_unpivoted['Date to DC'] = df_unpivoted.apply(lambda row: row['value'] if 'Date' in row['variable'] else None, axis=1)\n",
    "    \n",
    "    # Drop the variable and value columns\n",
    "    df_unpivoted.drop(columns=['variable', 'value'], inplace=True)\n",
    "    \n",
    "    # Drop rows where all three columns ('PO Cartons', 'PO qty', and 'Date to DC') are null\n",
    "    df_unpivoted.dropna(subset=['PO Cartons', 'PO qty', 'Date to DC'], how='all', inplace=True)\n",
    "\n",
    "    # Handle missing values in 'เรือ ETA'\n",
    "    df_unpivoted.fillna({\"เรือ ETA\": \"Unknown\"}, inplace=True) # Replace NaN with placeholder value\n",
    "\n",
    "    # Pivot the data back to combine rows with the same SHM_Item, CJ_Item, PO CJ No., PC_Cartons, and Ship to DC\n",
    "    final_import = df_unpivoted.groupby(\n",
    "        [\"SHM_Item\", \"CJ_Item\", \"Product Name\", \"PO CJ No.\", \"เรือ ETA\", \"PC_Cartons\", \"Ship to DC\"]\n",
    "    ).agg({\n",
    "        \"PO Cartons\": \"sum\",\n",
    "        \"PO qty\": \"sum\",\n",
    "        \"Date to DC\": \"first\"\n",
    "    }).reset_index()\n",
    "\n",
    "    # Restore 'เรือ ETA' to NaN if it was replaced with 'Unknown'\n",
    "    final_import[\"เรือ ETA\"] = final_import[\"เรือ ETA\"].replace(\"Unknown\", pd.NA)\n",
    "\n",
    "    # Rename columns\n",
    "    final_import.rename(columns={\n",
    "        'Date to DC': 'Delivery Date',\n",
    "        'PO qty': 'PO_Qty'\n",
    "    }, inplace=True)\n",
    "\n",
    "    return final_import\n",
    "\n",
    "# clean data for Access_PO\n",
    "def clean_access_po(df):\n",
    "    # Exclude unnecessary columns\n",
    "    df = df.drop(columns=['Devision','Unit','Customer'])\n",
    "    # Rename Column\n",
    "    df.rename(columns={\n",
    "        'PO Num': 'SHM PO No.',\n",
    "        'PO Ref': 'PO CJ No.',\n",
    "        'DC_Name': 'Ship to DC',\n",
    "        'Rec_Date': 'Delivery Date',\n",
    "        'Order Qty': 'PO Cartons',\n",
    "        'CJ_Description':'Product Name'\n",
    "    },inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Connect to Access database and fetch product details  \n",
    "def load_access_data():  \n",
    "    access_db_path = r'D:\\DataBase Access\\SHM_TMS_001_Master_Copy.accdb'  \n",
    "    conn_str = (  \n",
    "        r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'  \n",
    "        f'DBQ={access_db_path};'  \n",
    "    )  \n",
    "    try:  \n",
    "        conn = pyodbc.connect(conn_str)  \n",
    "        print(\"Connection successful\")\n",
    "\n",
    "        query = \"\"\"  \n",
    "        SELECT CJ_Item,  \n",
    "               SHM_Item,\n",
    "               [Supplier Name],\n",
    "               Devision\n",
    "          FROM qry_Product_List  \n",
    "        \"\"\"\n",
    "\n",
    "        access_df = pd.read_sql(query, conn)\n",
    "        conn.close()  \n",
    "        print(\"Connection to Access database is closed.\")  \n",
    "        return access_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Load DataFrame\n",
    "dataframes = load_data(po_file_path)\n",
    "cleaned_dataframes = {\n",
    "    'PO_HBA': clean_po_hba(dataframes['PO_HBA']),\n",
    "    'PO_Import': clean_po_import(dataframes['PO_Import']),\n",
    "    'Access_PO': clean_access_po(dataframes['Access_PO'])\n",
    "}\n",
    "# Append DataFrames together\n",
    "final_df = pd.concat(cleaned_dataframes.values(), ignore_index=True)\n",
    "final_df['CJ_Item'] = final_df['CJ_Item'].astype(str)\n",
    "final_df['SHM_Item'] = final_df['SHM_Item'].astype(str)\n",
    "\n",
    "# Load Access data\n",
    "access_df = load_access_data()\n",
    "if access_df is not None:\n",
    "    # Convert CJ_Item in access_df to string\n",
    "    access_df['CJ_Item'] = access_df['CJ_Item'].astype('Int64').astype(str)\n",
    "    access_df['SHM_Item'] = access_df['SHM_Item'].astype(str)\n",
    "\n",
    "    # Merge DataFrames\n",
    "    merged_df = pd.merge(final_df, access_df, on=['CJ_Item', 'SHM_Item'], how='left', suffixes=('', '_access'))\n",
    "\n",
    "    # Update Supplier Name in final_df where it is null\n",
    "    final_df['Supplier Name'] = final_df['Supplier Name'].fillna(merged_df['Supplier Name_access'])\n",
    "    final_df['Division'] = merged_df['Devision']\n",
    "\n",
    "# Load OwnerSCM\n",
    "owner_scm_file_path = r'C:\\Users\\Thanawit C\\OneDrive - Sahamit Product Co.,Ltd\\Data for Stock Report\\COPY_MasterLeadTime.xlsx'\n",
    "owner_scm_df = pd.read_excel(owner_scm_file_path, sheet_name='All_Product', header=1)\n",
    "\n",
    "# Cast column CJ_Item to str\n",
    "owner_scm_df['CJ_Item'] = owner_scm_df['CJ_Item'].astype(str)\n",
    "# Select some columns\n",
    "owner_scm_df_selected = owner_scm_df[['SHM_Item','CJ_Item','OwnerSCM','Base Lead Time (Days)']]\n",
    "owner_scm_df_selected['CJ_Item'] = owner_scm_df_selected['CJ_Item'].fillna('')\n",
    "owner_scm_df_selected['CJ_Item'] = owner_scm_df_selected['CJ_Item'].apply(lambda x: x.split('.')[0] if '.0' in str(x) else x)\n",
    "\n",
    "# Merge with Master Leadtime for get OwnerSCM\n",
    "final_df = pd.merge(final_df,owner_scm_df_selected[['CJ_Item','SHM_Item','OwnerSCM']],on=['CJ_Item','SHM_Item'],how='left')\n",
    "\n",
    "# Arrange column\n",
    "desire_order = [\n",
    "    'Division',\n",
    "    'OwnerSCM',\n",
    "    'PO Date',\n",
    "    'SHM PO No.',\n",
    "    'Supplier Name',\n",
    "    'SHM_Item',\n",
    "    'CJ_Item',\n",
    "    'Product Name',\n",
    "    'PO CJ No.',\n",
    "    'PC_Cartons',\n",
    "    'Ship to DC',\n",
    "    'PO Cartons',\n",
    "    'PO_Qty',\n",
    "    'เรือ ETA',\n",
    "    'Delivery Date',\n",
    "    'Delivery_Status'\n",
    "]\n",
    "final_df = final_df.reindex(columns=desire_order)\n",
    "final_df['เรือ ETA'] = pd.to_datetime(final_df['เรือ ETA'],errors='coerce')\n",
    "\n",
    "final_df_pivot = final_df.pivot_table(\n",
    "    index= ['CJ_Item','Ship to DC'],\n",
    "    values=['เรือ ETA','Delivery Date'],\n",
    "    aggfunc ='min'\n",
    ").reset_index().rename(columns={'เรือ ETA':'Min ETA','Delivery Date':'First Delivery Date'})\n",
    "\n",
    "final_df_pivot['ConcatIndex'] = final_df_pivot['CJ_Item'] + final_df_pivot['Ship to DC']\n",
    "\n",
    "\n",
    "# Save updated final_df to Excel\n",
    "save_directory = r'D:\\Data for Stock Report'\n",
    "file_name = \"Raw_PO_pending.xlsx\"\n",
    "save_path = os.path.join(save_directory, file_name)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(save_path, mode='w') as writer:\n",
    "    # Save final_df to the \"All PO Pending\" sheet\n",
    "    final_df.to_excel(writer, sheet_name='All PO Pending', index=False)\n",
    "    final_df_pivot.to_excel(writer, sheet_name='MIN ETA', index=False)\n",
    "\n",
    "print(f\"combine all po pending has been saved to: {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
