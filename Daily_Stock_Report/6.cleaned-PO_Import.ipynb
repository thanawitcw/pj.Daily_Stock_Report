{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is available. Proceeding with the processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thanawit C\\AppData\\Local\\Temp\\ipykernel_7640\\3759112868.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_columns.rename(columns={'Name' : 'Product Name',\n",
      "C:\\Users\\Thanawit C\\AppData\\Local\\Temp\\ipykernel_7640\\3759112868.py:86: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  access_data = pd.read_sql(query, conn)\n",
      "C:\\Users\\Thanawit C\\AppData\\Local\\Temp\\ipykernel_7640\\3759112868.py:110: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  access_data2 = pd.read_sql(query2, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHM_Item                       object\n",
      "CJ_Item                        object\n",
      "PO_Qty_to_DC1                 float64\n",
      "Min_del_date_to_DC1    datetime64[ns]\n",
      "PO_Qty_to_DC2                 float64\n",
      "Min_del_date_to_DC2    datetime64[ns]\n",
      "PO_Qty_to_DC4                 float64\n",
      "Min_del_date_to_DC4    datetime64[ns]\n",
      "dtype: object\n",
      "Connection to Access database closed.\n",
      "PO pending Import report has been saved to: D:\\Data for Stock Report\\cleaned_PO_pending_import_party.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import pyodbc\n",
    "from datetime import datetime\n",
    "\n",
    "def ensure_file_available(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"File is not available. Please check your file in OneDrive\")\n",
    "        return False\n",
    "    print(\"File is available. Proceeding with the processes\")\n",
    "    return True\n",
    "\n",
    "   \n",
    "def clean_and_groupby_file_PO_pending():\n",
    "    file_path = r'C:\\Users\\Thanawit C\\OneDrive - Sahamit Product Co.,Ltd\\Data for Stock Report\\COPY_Summary Forecast.xlsx'\n",
    "    save_path = r'D:\\Data for Stock Report\\cleaned_PO_pending_import_party.xlsx'\n",
    "    \n",
    "    ensure_file_available(file_path)\n",
    "\n",
    "    try:\n",
    "        # Attempt to read the Excel file\n",
    "        df2 = pd.read_excel(file_path, sheet_name='Summary Forecast', header=3)\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: {file_path}. Please check if the file is open or if you have access.\")\n",
    "        return\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}. Please check the file path.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Convert the specific columns to datetime\n",
    "    df2['แผนส่งเข้าคลังโพธาราม'] = pd.to_datetime(df2['แผนส่งเข้าคลังโพธาราม'], errors='coerce')\n",
    "    df2['แผนส่งเข้าคลังบางปะกง'] = pd.to_datetime(df2['แผนส่งเข้าคลังบางปะกง'], errors='coerce')\n",
    "    df2['แผนส่งเข้าคลังขอนแก่น'] = pd.to_datetime(df2['แผนส่งเข้าคลังขอนแก่น'], errors ='coerce')\n",
    "    df2['CJ_Item'] = df2['CJ_Item'].astype(str)\n",
    "\n",
    "    today = pd.to_datetime(datetime.now().date())\n",
    "    \n",
    "    # Filter Delviery date >= Today\n",
    "    df2_filtered = df2[(df2['แผนส่งเข้าคลังโพธาราม'] >= today) | (df2['แผนส่งเข้าคลังบางปะกง'] >= today) | (df2['แผนส่งเข้าคลังขอนแก่น'] >= today)]\n",
    "    \n",
    "    # Select needed columns\n",
    "    selected_columns = df2_filtered[['SHM_Item',\n",
    "                                      'CJ_Item',\n",
    "                                      'Name',\n",
    "                                      'PO CJ No.',\n",
    "                                      'เรือ ETA',\n",
    "                                      'แผนส่งเข้าคลังโพธาราม',\n",
    "                                      'ยอดสั่งโพธาราม(ลัง)',\n",
    "                                      'แผนส่งเข้าคลังบางปะกง',\n",
    "                                      'ยอดสั่งบางปะกง(ลัง)',\n",
    "                                      'แผนส่งเข้าคลังขอนแก่น',\n",
    "                                      'ยอดสั่งขอนแก่น(ลัง)']]\n",
    "    \n",
    "    # Rename columns\n",
    "    selected_columns.rename(columns={'Name' : 'Product Name',\n",
    "                                     'แผนส่งเข้าคลังโพธาราม': 'Date_to_DC1',\n",
    "                                     'ยอดสั่งโพธาราม(ลัง)': 'cartons_to_DC1',\n",
    "                                     'แผนส่งเข้าคลังบางปะกง': 'Date_to_DC2',\n",
    "                                     'ยอดสั่งบางปะกง(ลัง)': 'cartons_to_DC2',\n",
    "                                     'แผนส่งเข้าคลังขอนแก่น': 'Date_to_DC4',\n",
    "                                     'ยอดสั่งขอนแก่น(ลัง)': 'cartons_to_DC4'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Step to connect to Access database and load data\n",
    "    access_db_path = r'D:\\DataBase Access\\SHM_TMS_001_Master_Copy.accdb'  # Updated Access DB path\n",
    "    connection_string = f\"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={access_db_path};\"\n",
    "\n",
    "    conn = None\n",
    "    \n",
    "    try:\n",
    "        # Connect to Access database\n",
    "        conn = pyodbc.connect(connection_string)\n",
    "        \n",
    "        # Load data from Access\n",
    "        query = \"\"\"\n",
    "        SELECT SHM_Item,\n",
    "               CJ_Item,\n",
    "               PC_Cartons\n",
    "        FROM qry_Product_List\n",
    "        \"\"\"\n",
    "\n",
    "        access_data = pd.read_sql(query, conn)\n",
    "\n",
    "        query2 = \"\"\"\n",
    "        SELECT [PO Date],\n",
    "               [PO Num],\n",
    "               [PO Ref],\n",
    "               [Supplier Name],\n",
    "               Item as SHM_Item,\n",
    "               CJ_Item,\n",
    "               CJ_Description as [Product Name],\n",
    "               Devision,\n",
    "               PC_Cartons,\n",
    "               Rec_Date,\n",
    "               [Order Qty],\n",
    "               Unit,\n",
    "               Delivery_Status, \n",
    "               Customer, \n",
    "               DC_Name\n",
    "        FROM qry_Output_For_Excel_New \n",
    "        WHERE Delivery_Status IS NULL\n",
    "        AND Customer = 'CJ'\n",
    "        AND Devision in ('Import-Foods', 'Import-NF')\n",
    "        \"\"\"\n",
    "\n",
    "        access_data2 = pd.read_sql(query2, conn)\n",
    "        access_data2.rename(columns={'PO Ref': 'PO CJ No.'}, inplace=True)\n",
    "\n",
    "        dc_name_mapping = {\n",
    "            'CJ DC1 ราชบุรี': 'DC1',\n",
    "            'CJ DC2 บางปะกง': 'DC2',\n",
    "            'DC โพธาราม': 'DC1',\n",
    "            'DC บางวัว 1': 'DC2',\n",
    "            'DC ขอนแก่น': 'DC4',\n",
    "            'DC บางวัว 2': 'TD09'\n",
    "        }\n",
    "        access_data2['DC_Name'] = access_data2['DC_Name'].replace(dc_name_mapping)\n",
    "        # Create new column for PO_Qty with condition on Unit\n",
    "        access_data2['PO_Qty'] = access_data2.apply(lambda row: row['Order Qty'] * row['PC_Cartons'] if row['Unit'] == 'ลัง' else row['Order Qty'], axis=1)\n",
    "        # Create new column for PO_Ctn with condition on Unit\n",
    "        access_data2['PO_CTN'] = access_data2.apply(lambda row: row['Order Qty'] if row['Unit'] == 'ลัง' else row['Order Qty'] / row['PC_Cartons'], axis=1)\n",
    "        \n",
    "    \n",
    "        pivot_df = access_data2.pivot_table(\n",
    "            index=['SHM_Item', 'CJ_Item', 'Product Name','PO CJ No.'],\n",
    "            columns = 'DC_Name',\n",
    "            values= 'PO_Qty',\n",
    "            aggfunc='sum'\n",
    "        ).reset_index()\n",
    "        pivot_df.columns = ['SHM_Item', 'CJ_Item', 'Product Name','PO CJ No.'] + [f'PO_Qty_to_{col}' for col in pivot_df.columns[4:]]\n",
    "\n",
    "        pivot_df2 = access_data2.pivot_table(\n",
    "            index=['SHM_Item', 'CJ_Item', 'Product Name','PO CJ No.'],\n",
    "            columns = 'DC_Name',\n",
    "            values= 'PO_CTN',\n",
    "            aggfunc='sum'\n",
    "        ).reset_index()\n",
    "        pivot_df2.columns = ['SHM_Item', 'CJ_Item', 'Product Name','PO CJ No.'] + [f'cartons_to_{col}' for col in pivot_df2.columns[4:]]\n",
    "\n",
    "        pivot_df3 = access_data2.pivot_table(\n",
    "            index=['SHM_Item', 'CJ_Item', 'Product Name','PO CJ No.'],\n",
    "            columns='DC_Name',\n",
    "            values='Rec_Date',\n",
    "            aggfunc='min'\n",
    "        ).reset_index()\n",
    "        pivot_df3.columns = ['SHM_Item', 'CJ_Item', 'Product Name','PO CJ No.'] + [f'Date_to_{col}' for col in pivot_df3.columns[4:]]\n",
    "\n",
    "        # MERGE 2 pivot tables\n",
    "        merged_df = pd.merge(pivot_df, pivot_df2, on=['SHM_Item', 'CJ_Item', 'Product Name','PO CJ No.'], how='left')\n",
    "        merged_df2 = pd.merge(merged_df, pivot_df3, on=['SHM_Item', 'CJ_Item', 'Product Name','PO CJ No.'], how='left')\n",
    "        \n",
    "        # Merge Access data with the selected columns\n",
    "        cleaned_data = pd.merge(selected_columns, access_data[['CJ_Item', 'SHM_Item', 'PC_Cartons']], on=['CJ_Item', 'SHM_Item'], how='left')\n",
    "\n",
    "\n",
    "        # Calculate new columns\n",
    "        cleaned_data['PO_Qty_to_DC1'] = cleaned_data['cartons_to_DC1'] * cleaned_data['PC_Cartons']\n",
    "        cleaned_data['PO_Qty_to_DC2'] = cleaned_data['cartons_to_DC2'] * cleaned_data['PC_Cartons']\n",
    "        cleaned_data['PO_Qty_to_DC4'] = cleaned_data['cartons_to_DC4'] * cleaned_data['PC_Cartons']\n",
    "\n",
    "        cleaned_data['PO CJ No.'] = cleaned_data['PO CJ No.'].astype(str) \n",
    "\n",
    "        # Identify the PO CJ No. values that are already present in cleaned_data\n",
    "        existing_po_cj_no = cleaned_data['PO CJ No.'].unique()\n",
    "\n",
    "        # Filter out rows from merged_df2 where PO CJ No. is already in cleaned_data\n",
    "        merged_df2_filtered = merged_df2[~merged_df2['PO CJ No.'].isin(existing_po_cj_no)]\n",
    "\n",
    "        # Combine the cleaned data with the filtered pivot data\n",
    "        combined_data = pd.concat([cleaned_data, merged_df2_filtered], ignore_index=True)\n",
    "\n",
    "\n",
    "        # Group the cleaned data for the pivot table\n",
    "        pivot_data = combined_data.groupby(['SHM_Item', 'CJ_Item']).agg({\n",
    "            'PO_Qty_to_DC1': 'sum',\n",
    "            'Date_to_DC1' : 'min',\n",
    "            'PO_Qty_to_DC2': 'sum',\n",
    "            'Date_to_DC2' : 'min',\n",
    "            'PO_Qty_to_DC4': 'sum',\n",
    "            'Date_to_DC4' : 'min'\n",
    "        }).reset_index()  # Reset index to keep grouping columns as regular columns\n",
    "\n",
    "        # Rename the columns to match the desired output\n",
    "        pivot_data.rename(columns={\n",
    "            'Date_to_DC1': 'Min_del_date_to_DC1',\n",
    "            'Date_to_DC2': 'Min_del_date_to_DC2',\n",
    "            'Date_to_DC4': 'Min_del_date_to_DC4'\n",
    "        }, inplace=True)\n",
    "\n",
    "        print(pivot_data.dtypes)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while connecting to Access: {e}\")\n",
    "        return\n",
    "    finally:\n",
    "        # Ensure the connection is closed after processing\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print(\"Connection to Access database closed.\")\n",
    "\n",
    "\n",
    "    # Write the cleaned data with new calculations to the Excel file\n",
    "    try:\n",
    "        with pd.ExcelWriter(save_path, mode='w') as writer:  # Use mode 'w' to write new data without overwriting\n",
    "            pivot_data.to_excel(writer, sheet_name='Pivot Import', index=False)\n",
    "            combined_data.to_excel(writer, sheet_name='cleaned data', index=False)\n",
    "            merged_df2_filtered.to_excel(writer, sheet_name='cleaned data_fromAccess', index=False)\n",
    "        print(f\"PO pending Import report has been saved to: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the file: {e}\")\n",
    "\n",
    "# Run the function\n",
    "clean_and_groupby_file_PO_pending()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
